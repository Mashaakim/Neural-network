{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Двухслойная нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача:\n",
    "- Реализовать слои Sigmoid, Dense, Softmax, LogLoss с использование тензоров pytorch\n",
    "- Реализовать двухслойную нейронную сеть для распознования цифр MNIST\n",
    "- Обучить сеть. Обученная модель должна побить baseline на kaggle. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import FloatTensor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return 1./(1+torch.exp(-x))\n",
    "    \n",
    "    def backward(self, dz, lr):\n",
    "        sm = self.forward(self.x)\n",
    "        self.lp = sm*(1 - sm)\n",
    "        return dz * self.lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense:\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.w = torch.rand(out_size, in_size)/10000\n",
    "        self.th = torch.rand(out_size)/10000\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return self.w @ self.x.float() + self.th\n",
    "    \n",
    "    def backward(self, dz, lr):\n",
    "        ret = torch.t(self.w) @ dz\n",
    "        self.w = torch.addr(1 , self.w ,-lr, dz, self.x.float())\n",
    "        self.th -= lr * dz\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return torch.exp(x) / torch.sum(torch.exp(x))\n",
    "    \n",
    "    def backward(self, dz, lr):\n",
    "        \n",
    "        sm = self.forward(self.x)\n",
    "        df = sm * torch.t((torch.eye(sm.size()[0]) - sm))\n",
    "        return torch.matmul(dz, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogLoss:\n",
    "    \n",
    "    def forward(self, y_true, y_hat):\n",
    "        y = torch.zeros(10)\n",
    "        y[int(y_true)] = 1\n",
    "        self.y_true = y\n",
    "        self.y_hat = y_hat\n",
    "        return torch.sum( y * torch.log(y_hat) * (-1))\n",
    "    \n",
    "    def backward(self, dz, lr=0.001):\n",
    "        return dz * (-1) * self.y_true / self.y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return torch.max(0, x)\n",
    "\n",
    "    def backward(self, dz, lr=0.1):\n",
    "        dz[self.x < 0] = 0\n",
    "        return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net():\n",
    "    def __init__(self, in_size, hidden_lay_size, out_size):\n",
    "        self.s = Softmax()\n",
    "        self.d1 = Dense(in_size, hidden_lay_size)\n",
    "        self.sg = Sigmoid()\n",
    "        self.d2 = Dense(hidden_lay_size, out_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        net = self.d1.forward(x)\n",
    "        net = self.sg.forward(net)\n",
    "        net = self.d2.forward(net)\n",
    "        net = self.s.forward(net)\n",
    "        \n",
    "        return net\n",
    "    \n",
    "    def backward(self, dz, lr):\n",
    "        dz = self.s.backward(dz, lr)\n",
    "        dz = self.d2.backward(dz, lr)\n",
    "        dz = self.sg.backward(dz, lr)\n",
    "        dz = self.d1.backward(dz, lr)\n",
    "        \n",
    "        return dz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train,y_test = train_test_split(mnist['data']/255, mnist['target'], test_size = 0.3)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "Y_train = torch.FloatTensor(y_train)\n",
    "Y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем сеть на CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(784, 100, 10)\n",
    "loss = LogLoss()\n",
    "lr = 0.01\n",
    "\n",
    "def train(net, loss, lr, n_epoch):\n",
    "    L = []\n",
    "    for epoch in range(n_epoch):\n",
    "        L_acc = 0.\n",
    "        arr = numpy.arange(X_train.size(0))\n",
    "        numpy.random.shuffle(arr)\n",
    "        for i in arr:\n",
    "            y_h = net.forward(X_train[i])\n",
    "            L_acc += loss.forward(Y_train[i], y_h)\n",
    "            \n",
    "            dz = loss.backward(1, lr)\n",
    "            net.backward(dz, lr)\n",
    "        L.append(L_acc)\n",
    "    return L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 193m 47s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "L = train(net, loss, 0.01, 10)\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s \\n'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9726003b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 4.1824e-07\n",
      " 5.5800e-07\n",
      " 8.4162e-05\n",
      " 3.7316e-07\n",
      " 4.5450e-06\n",
      " 2.0764e-05\n",
      " 9.9988e-01\n",
      " 2.3911e-09\n",
      " 9.0491e-06\n",
      " 1.3578e-07\n",
      "[torch.FloatTensor of size 10]\n",
      " \n",
      " 1.1335e-07\n",
      " 6.5384e-08\n",
      " 8.1896e-07\n",
      " 2.1154e-07\n",
      " 9.9950e-01\n",
      " 2.5675e-05\n",
      " 1.6937e-06\n",
      " 1.8505e-04\n",
      " 4.8644e-05\n",
      " 2.4193e-04\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "plt.plot(L) # посмотрим на кривую обучения\n",
    "plt.show()\n",
    "print( net.forward(X_train[0]), net.forward(X_train[1])) # проверим глазами, что обучились"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сохраняем результат для kaggle\n",
    "\n",
    "https://www.kaggle.com/c/track-nn-2018-spring-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Загрузки/mnist_train.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('./Загрузки/mnist_test.pkl', 'rb') as d:\n",
    "    test = pickle.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = train['data']\n",
    "Y1_train = train['target']\n",
    "X1_train = torch.FloatTensor(X1_train)/255\n",
    "Y1_train = torch.FloatTensor(Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(784, 100, 10)\n",
    "loss = LogLoss()\n",
    "lr = 0.01\n",
    "\n",
    "\n",
    "def train(net, loss, lr, n_epoch):\n",
    "    L = []\n",
    "    for epoch in range(n_epoch):\n",
    "        L_acc = 0.\n",
    "        arr = numpy.arange(X1_train.size(0))\n",
    "        numpy.random.shuffle(arr)\n",
    "        for i in arr:\n",
    "            y_h = net.forward(X1_train[i])\n",
    "            L_acc += loss.forward(Y1_train[i], y_h)\n",
    "            \n",
    "            dz = loss.backward(1, lr)\n",
    "            net.backward(dz, lr)\n",
    "        L.append(L_acc)\n",
    "    return L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 49m 16s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "L = train(net, loss, lr, 5)\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s \\n'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = test['data']\n",
    "X1_test = torch.FloatTensor(X1_test)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./masha_test.csv', 'wt') as f:\n",
    "    f.write('id,p0,p1,p2,p3,p4,p5,p6,p7,p8,p9\\n')\n",
    "    for i in range(X1_test.shape[0]):\n",
    "        v = net.forward(X1_test[i])\n",
    "        f.write(','.join([str(i)] + list(map(str, v.tolist()))) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
